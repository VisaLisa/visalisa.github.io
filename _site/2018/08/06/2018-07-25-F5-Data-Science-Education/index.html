<h2 id="content">Content</h2>
<ol>
  <li><a href="#intro">Introduction</a></li>
  <li><a href="#explo">Explore</a></li>
  <li><a href="#prin">Principles</a></li>
  <li><a href="#cluster">Clustering Data</a></li>
  <li><a href="#ref">Reference</a></li>
</ol>

<h1 id="introduction-">Introduction <a name="intro"></a></h1>

<p>Trying to find information using this <a href="https://archive.ics.uci.edu/ml/datasets/Wholesale+customers">dataset</a>. We selected these catorgories: frescos (<code class="highlighter-rouge">Fresh</code>), leite (<code class="highlighter-rouge">Milk</code>), mercearia (<code class="highlighter-rouge">Grocery</code>), congelado (<code class="highlighter-rouge">Frozen</code>), detergente e papel (<code class="highlighter-rouge">Detergents_Paper</code>) e Delicatessen (<code class="highlighter-rouge">Delicatessen</code>). O objetivo aqui será entender melhor a estrutura desses gastos, como eles se relacionam e se há algum padrão que pode ser explorado para otimizar as vendas.</p>

<h1 id="explore-">Explore <a name="explo"></a></h1>

<p>Em primeiro lugar, vamos explorar algumas estatísticas simples dos nossos dados, tais como média de gastos por produto, desvio padrão e quantis dos dados.</p>

<table class="table table-striped table-bordered table-hover" style="text-align: center;">
  <thead>
    <tr>
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Média</th>
      <td>12000.29</td>
      <td>5796.26</td>
      <td>7951.27</td>
      <td>3071.93</td>
      <td>2881.49</td>
      <td>1524.87</td>
    </tr>
    <tr>
      <th>Desvio Padrão</th>
      <td>12647.33</td>
      <td>7380.38</td>
      <td>9503.16</td>
      <td>4854.67</td>
      <td>4767.85</td>
      <td>2820.10</td>
    </tr>
    <tr>
      <th>Mín.</th>
      <td>3.00</td>
      <td>55.00</td>
      <td>3.00</td>
      <td>25.00</td>
      <td>3.00</td>
      <td>3.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>3127.75</td>
      <td>1533.00</td>
      <td>2153.00</td>
      <td>742.25</td>
      <td>256.75</td>
      <td>408.25</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>8504.00</td>
      <td>3627.00</td>
      <td>4755.50</td>
      <td>1526.00</td>
      <td>816.50</td>
      <td>965.50</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>16933.75</td>
      <td>7190.25</td>
      <td>10655.75</td>
      <td>3554.25</td>
      <td>3922.00</td>
      <td>1820.25</td>
    </tr>
    <tr>
      <th>Máx.</th>
      <td>112151.00</td>
      <td>73498.00</td>
      <td>92780.00</td>
      <td>60869.00</td>
      <td>40827.00</td>
      <td>47943.00</td>
    </tr>
  </tbody>
</table>

<p>Podemos ver que, em média, a maioria dos gastos dos consumidores é com frescos. Em seguida, gasta-se mais com mercearia, leite, congelados, detergente/papel e delicatssen, nessa ordem. Além disso, os gastos com delicatssen são bem menores do que os com outros produtos.</p>

<p>Usando um <a href="https://matheusfacure.github.io/2017/02/15/MQO-formula-analitica/">modelo de previsão linear simples</a>, notei que 70% dos gastos com mercearia (<code class="highlighter-rouge">Grocery</code>) pode ser explicado pelos gastos nos outros produtos. Isso torna a variável de mercearia parcialmente redundante nos dados. Se tivéssemos muitas variáveis, por eficiência computacional, seria uma boa retirá-la dos dados. Como só temos 6 variáveis, vamos mantê-la. Em seguida, apliquei o logaritmo natural em todas as variáveis. Isso faz com que a distribuição delas fique melhor comportada, isto é, mais próxima de uma gaussiana (curva de sino). Após essa etapa de processamento, coloquei as distribuições e as correlações das variáveis num gráfico.</p>

<p><img class="img-responsive center-block thumbnail" src="/img/portfolio/un-ml-client/relacoes-gastos.png" alt="relacoes-gastos" /></p>

<p>Aparentemente, há uma elevada correlação entre <code class="highlighter-rouge">Grocery</code> e <code class="highlighter-rouge">Detergents_Paper</code>; há também alguma correlação entre <code class="highlighter-rouge">Grocery</code> e <code class="highlighter-rouge">Milk</code> e entre <code class="highlighter-rouge">Milk</code> e <code class="highlighter-rouge">Detergents_Paper</code>. Isso já nos dá alguma informação sobre o comportamento dos consumidores: quando eles compram produtos de mercearia (<code class="highlighter-rouge">Grocery</code>), tendem também a comprar produtos nas categorias papel/detergente e leite. Mais ainda, essas correlações confirmam o que havíamos visto antes, sobre gastos com mercearia serem um tanto redundantes.</p>

<h1 id="principles-">Principles <a name="Prin"></a></h1>

<p>A análise de componentes principais é um método de extração de características que busca achar os (tãn tãn tãn tãn!!!) componentes principais dos dados. Como um exemplo super simples, digamos que os consumidores do atacado em questão sejam apenas mães ou pais de crianças pequenas. Nos dados, só temos as quantidades gastas desses consumidores, mas podemos imaginar que esses gastos são manifestações de características que não podemos observar, como estilo de vida. O que podemos fazer então é combinar as nossas variáveis observadas (gastos) para criar variáveis explicativas que melhor condensam os padrões de consumo. Por exemplo, se notarmos que gastos com fraldas e leite em pó variam junto, podemos combinar essas duas variáveis em um único componente, que captura certa essência do fator não observável hábito de consumo de uma família com crianças pequenas. Com isso, reduzimos o número de variáveis nos dados, mas mantemos a informação presente neles: em vez de precisarmos acompanhar duas variáveis de gastos, só precisaremos acompanhar a variação desse novo componente criado. Intuitivamente, podemos pensar nesse componente como representando um fator latente de variação nos dados observáveis. Talvez esse fator latente seja estrutura familiar, mas, de qualquer forma o importante é que ele ajude a explicar variações de consumo.</p>

<p>Análise de Componentes Principais (ACP) faz justamente isso. Essa técnica maximiza a variação dos dados nos componentes extraídos, ao mesmo tempo que minimiza o erro de reconstrução, isto é, minimiza a perda de informação que se tem ao manter apenas os componentes principais mais importantes, descartando-se os demais. Usando ACP, substituímos nossas 6 variáveis observáveis em seis componentes principais, sendo que os primeiros componentes explicam a maioria da variação nos dados originais, isto é, no consumo. Podemos inclusive ver como as variáveis originais são utilizadas para criar esses componentes.</p>

<p><img class="img-responsive center-block thumbnail" src="/img/portfolio/un-ml-client/PCA-composicao.png" alt="PCA1" /></p>

<p>Note como 71,9% (0,4424 + 0,2766) da variação nos dados pode ser explicada pelos dois primeiros componentes principais e como os quatro primeiros explicam 93,14% dessa variância. O primeiro componente principal é composto majoritariamente por <code class="highlighter-rouge">Detergent_Paper</code> e um pouco por <code class="highlighter-rouge">Milk</code> e <code class="highlighter-rouge">Grocery</code>. A partir deste componente principal, podemos ver que os clientes que gastam mais com leite tendem a gastar mais em mercearia e em detergente/papel. Também mostra que os clientes diferem principalmente pela diferença nos gastos com esses três produtos. O segundo componente principal, por sua vez, é composto principalmente por <code class="highlighter-rouge">Fresh</code>, <code class="highlighter-rouge">Frozen</code> e <code class="highlighter-rouge">Delicatssen</code>. Isso mostra que a segunda maior fonte de diferença entre os clientes vem de seus gastos com produtos frescos, congelados e delicatssen. A partir desse componente principal, podemos inferir que os clientes que gastam mais em frescos também tendem a gastar mais em congelados e delicatssen. O mesmo raciocínio pode ser feito para os outros componentes extraídos. Antes de prosseguir, descartei todos os componentes principais menos os dois primeiros. Isso resulta em certa perda de informação, mas nada grave, já que eles sozinhos preservam quase 72% da informação original. Como só estamos com dois componentes principais, podemos colocá-los em um gráfico e visualizar como as variáveis originais de consumo estão relacionadas com os dois primeiros componentes principais.</p>

<p><img class="img-responsive center-block thumbnail" src="/img/portfolio/un-ml-client/PCA-biplot.png" alt="PCA2" /></p>

<p>Claramente, quanto mais negativo for o primeiro componente principal de uma observação, mais esse consumidor compra leite, produtos de mercearia e detergente/papel. Além disso, consumidores com o primeiro componente principal positivo compram menos de todas as categorias de produtos, o que me leva a crer que são, provavelmente, estabelecimentos menores. Com o mesmo tipo de raciocínio, podemos dizer que consumidores cujo segundo componente principal é negativo compram mais frescos, congelados e delicatssen.</p>

<h1 id="clustering-data-">Clustering Data <a name="cluster"></a></h1>

<p>Com os dados reduzidos, prossegui para algoritmos de clusterização, para tentar identificar segmentos de mercado. O método usado foi de <a href="https://www.youtube.com/watch?v=REypj2sy_5U">Expectativa-Maximização</a>, que identifica <em>clusters</em> de forma iterativa. O número ótimo de <em>clusters</em> encontrado foi dois.</p>

<p><img class="img-responsive center-block thumbnail" src="/img/portfolio/un-ml-client/GMM-biplot.png" alt="GMM" /></p>

<p>How we cluster data.</p>

<h1 id="reference-">Reference <a name="ref"></a></h1>

<p>Este trabalho é uma adaptação do terceiro projeto do <a href="https://br.udacity.com/course/machine-learning-engineer-nanodegree--nd009/?gclid=Cj0KEQjw9r7JBRCj37PlltTskaMBEiQAKTzTfFcElVRXhgn0LpGDkFgyBmi0C71whULjIq3rpRANFusaAtlH8P8HAQ">Nanodegree Engenheiro de Machine Learning da Udacity</a>.</p>

<p>Você pode conferir a implementação completa do projeto <a href="https://github.com/matheusfacure/Tutoriais-de-AM/tree/master/Exemplos">no GitHub</a>.</p>
